# 网络爬虫
### 从哪开始？根集
爬虫开始访问的URL初始集合被称作根集（root set），从足够多的不同网站中选择URL，这样爬变所有的连接才能到达大部分你刚兴趣的web页面。

### 链接的提取以及相对链接的标准化
不停地对HTML页面进行解析，将链接提取出来，并将相对URL转换为绝对形式。

### 避免环路的出现
机器人必须知道它到过何处，以避免环路的出现

### 循环与复制
环路对爬虫是有害的：
- 他们会使爬虫陷入可能会将其困住的循环之中
- 爬冲不断的获取相同的页面时，另一端的web服务器也在遭受着打击。
- 即使循环自身不是什么问题，爬虫也是在获取大量重复的页面

### 面包屑留下的痕迹
- 树和散列表
- 有损存在位图
- 检查点
- 分类

### 别名与机器人环路
如果连个URL看起来不一样，但实际指向的是同一资源，就称这两个URL互为别名。

### 规范 化URL
1. 如果没有指定端口，就向主机中添加“：80”。
2. 将所有转义符%xx都换成等价字符
3. 删除#标签

### 文件系统环路

### 动态虚拟web空间

### 避免循环和重复
爬虫的自动化程度越高（人为监管越少），越可能陷入麻烦之中
- 规范化URL
- 广度先行的爬虫
- 节流
- 限制URL的大小
- URL/站点黑名单
- 模式检测
- 内容指纹
- 人工监视
